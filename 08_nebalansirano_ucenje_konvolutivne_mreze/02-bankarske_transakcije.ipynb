{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from imblearn import over_sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Ucitati podatke iz datoteke *creditcard.csv* u kojoj se nalaze podaci o bankarskim transakcijama i njihova klasifikacija na regularne i neregularne transakcije.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...         V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  ...   -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425  ...   -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  ...    0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024  ...   -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  ...   -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10',\n",
       "       'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20',\n",
       "       'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount',\n",
       "       'Class'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Ispisati broj instanci koje pripadaju ovim klasama. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>284315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Number of\n",
       "Class           \n",
       "0         284315\n",
       "1            492"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report = data[['Time', 'Class']].groupby('Class').count()\n",
    "report = report.rename(index=str, columns={'Time': 'Number of'})\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-151d583987cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Class'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "data['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = data['Class'].count()\n",
    "n_regular = data['Class'].value_counts()[0]\n",
    "n_fraud = data['Class'].value_counts()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total:  284807\n",
      "Regular:  284315\n",
      "Fraud:  492\n",
      "Ratio of regular ones:  0.99827\n",
      "Ratio of fraud ones:  0.00173\n"
     ]
    }
   ],
   "source": [
    "print('Total: ', n)\n",
    "print('Regular: ', n_regular)\n",
    "print('Fraud: ', n_fraud)\n",
    "print('Ratio of regular ones: ', round(n_regular / n, 5))\n",
    "print('Ratio of fraud ones: ', round(n_fraud / n, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Number of instances')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar([0, 1], [n_regular, n_fraud], color=['red', 'green'])\n",
    "plt.xticks([0, 1], ['Number of regular ts', 'Number of fraud ts'])\n",
    "plt.ylabel('Number of instances')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Pripremiti skupove podataka za ucenje. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (284807, 29)\n",
      "Shape of y: (284807, 1)\n"
     ]
    }
   ],
   "source": [
    "data = data.drop(['Time'], axis=1)\n",
    "X = np.array(data.drop(['Class'], axis=1))\n",
    "y = np.array(data[['Class']])\n",
    "print('Shape of X: {}'.format(X.shape))\n",
    "print('Shape of y: {}'.format(y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number transactions X_train dataset:  (199364, 29)\n",
      "Number transactions y_train dataset:  (199364, 1)\n",
      "Number transactions X_test dataset:  (85443, 29)\n",
      "Number transactions y_test dataset:  (85443, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "print(\"Number transactions X_train dataset: \", X_train.shape)\n",
    "print(\"Number transactions y_train dataset: \", y_train.shape)\n",
    "print(\"Number transactions X_test dataset: \", X_test.shape)\n",
    "print(\"Number transactions y_test dataset: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.132066</td>\n",
       "      <td>0.107044</td>\n",
       "      <td>-0.650588</td>\n",
       "      <td>-0.996032</td>\n",
       "      <td>1.814333</td>\n",
       "      <td>1.740740</td>\n",
       "      <td>0.496852</td>\n",
       "      <td>0.633016</td>\n",
       "      <td>0.017181</td>\n",
       "      <td>-0.362707</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062612</td>\n",
       "      <td>-0.062489</td>\n",
       "      <td>0.005292</td>\n",
       "      <td>0.251519</td>\n",
       "      <td>-2.466810</td>\n",
       "      <td>-0.889690</td>\n",
       "      <td>0.337462</td>\n",
       "      <td>0.306395</td>\n",
       "      <td>0.074817</td>\n",
       "      <td>47.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.125994</td>\n",
       "      <td>0.014207</td>\n",
       "      <td>-1.514760</td>\n",
       "      <td>0.115021</td>\n",
       "      <td>0.598510</td>\n",
       "      <td>-0.333235</td>\n",
       "      <td>0.199289</td>\n",
       "      <td>-0.264353</td>\n",
       "      <td>0.384111</td>\n",
       "      <td>0.028747</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.086076</td>\n",
       "      <td>-0.329368</td>\n",
       "      <td>-0.788150</td>\n",
       "      <td>0.267730</td>\n",
       "      <td>0.066122</td>\n",
       "      <td>-0.135785</td>\n",
       "      <td>0.203841</td>\n",
       "      <td>-0.068267</td>\n",
       "      <td>-0.057678</td>\n",
       "      <td>1.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.086694</td>\n",
       "      <td>0.166240</td>\n",
       "      <td>1.573127</td>\n",
       "      <td>0.687266</td>\n",
       "      <td>0.222359</td>\n",
       "      <td>1.102606</td>\n",
       "      <td>1.575093</td>\n",
       "      <td>-1.098608</td>\n",
       "      <td>0.763887</td>\n",
       "      <td>1.404677</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052960</td>\n",
       "      <td>0.015324</td>\n",
       "      <td>1.063663</td>\n",
       "      <td>-0.410841</td>\n",
       "      <td>0.722723</td>\n",
       "      <td>-0.171733</td>\n",
       "      <td>-0.613543</td>\n",
       "      <td>-1.201571</td>\n",
       "      <td>-1.139931</td>\n",
       "      <td>170.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.352339</td>\n",
       "      <td>-0.534984</td>\n",
       "      <td>0.555143</td>\n",
       "      <td>-0.629355</td>\n",
       "      <td>-1.144170</td>\n",
       "      <td>-0.852967</td>\n",
       "      <td>-0.642128</td>\n",
       "      <td>-0.032659</td>\n",
       "      <td>-0.654482</td>\n",
       "      <td>0.619206</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.066712</td>\n",
       "      <td>-0.014814</td>\n",
       "      <td>-0.180379</td>\n",
       "      <td>0.178112</td>\n",
       "      <td>0.347720</td>\n",
       "      <td>0.151810</td>\n",
       "      <td>-0.404361</td>\n",
       "      <td>0.013746</td>\n",
       "      <td>0.016152</td>\n",
       "      <td>5.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.526760</td>\n",
       "      <td>0.647782</td>\n",
       "      <td>0.615391</td>\n",
       "      <td>-0.561114</td>\n",
       "      <td>0.836950</td>\n",
       "      <td>-0.514251</td>\n",
       "      <td>0.984325</td>\n",
       "      <td>-0.097430</td>\n",
       "      <td>-0.062634</td>\n",
       "      <td>-1.033567</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.073333</td>\n",
       "      <td>-0.221533</td>\n",
       "      <td>-0.393158</td>\n",
       "      <td>-0.214990</td>\n",
       "      <td>0.588447</td>\n",
       "      <td>0.679496</td>\n",
       "      <td>0.518434</td>\n",
       "      <td>0.065022</td>\n",
       "      <td>0.147294</td>\n",
       "      <td>89.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0 -0.132066  0.107044 -0.650588 -0.996032  1.814333  1.740740  0.496852   \n",
       "1  2.125994  0.014207 -1.514760  0.115021  0.598510 -0.333235  0.199289   \n",
       "2 -0.086694  0.166240  1.573127  0.687266  0.222359  1.102606  1.575093   \n",
       "3  1.352339 -0.534984  0.555143 -0.629355 -1.144170 -0.852967 -0.642128   \n",
       "4 -1.526760  0.647782  0.615391 -0.561114  0.836950 -0.514251  0.984325   \n",
       "\n",
       "         7         8         9    ...          19        20        21  \\\n",
       "0  0.633016  0.017181 -0.362707   ...   -0.062612 -0.062489  0.005292   \n",
       "1 -0.264353  0.384111  0.028747   ...   -0.086076 -0.329368 -0.788150   \n",
       "2 -1.098608  0.763887  1.404677   ...    0.052960  0.015324  1.063663   \n",
       "3 -0.032659 -0.654482  0.619206   ...   -0.066712 -0.014814 -0.180379   \n",
       "4 -0.097430 -0.062634 -1.033567   ...   -0.073333 -0.221533 -0.393158   \n",
       "\n",
       "         22        23        24        25        26        27      28  \n",
       "0  0.251519 -2.466810 -0.889690  0.337462  0.306395  0.074817   47.89  \n",
       "1  0.267730  0.066122 -0.135785  0.203841 -0.068267 -0.057678    1.98  \n",
       "2 -0.410841  0.722723 -0.171733 -0.613543 -1.201571 -1.139931  170.10  \n",
       "3  0.178112  0.347720  0.151810 -0.404361  0.013746  0.016152    5.96  \n",
       "4 -0.214990  0.588447  0.679496  0.518434  0.065022  0.147294   89.95  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vrsimo normalizaciju atributa Value, odnosno vrednosti transakcije. Vazno je da smo prvo\n",
    "izvrsili podelu podataka na skup za obucavanja i testiranje kako informacije iz skupa za obucavanje\n",
    "ne bi uplivale u skup za testiranje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(X_train[:, -1].reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[:, -1] = scaler.transform(X_train[:, -1].reshape(-1, 1)).reshape(-1,)\n",
    "X_test[:, -1] = scaler.transform(X_test[:, -1].reshape(-1, 1)).reshape(-1,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Primeniti algoritam logisticke regresije i prikazati klasifikacioni izvestaj. Sta nije u redu? Koju meru ima smisla koristiti?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_classification(clf, X_train, y_train, X_test, y_test):\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_train_pred = clf.predict(X_train)\n",
    "    y_test_pred = clf.predict(X_test)\n",
    "    \n",
    "    print('Train confusion matrix:\\n', metrics.confusion_matrix(y_train, y_train_pred), '\\n')\n",
    "    print('Test confusion matrix:\\n', metrics.confusion_matrix(y_test, y_test_pred), '\\n')\n",
    "    \n",
    "    print('Train classification report:\\n', metrics.classification_report(y_train, y_train_pred), '\\n')\n",
    "    print('Test classification report:\\n', metrics.classification_report(y_test, y_test_pred), '\\n')\n",
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/lib/python3.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train confusion matrix:\n",
      " [[198990     29]\n",
      " [   131    214]] \n",
      "\n",
      "Test confusion matrix:\n",
      " [[85284    12]\n",
      " [   56    91]] \n",
      "\n",
      "Train classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    199019\n",
      "           1       0.88      0.62      0.73       345\n",
      "\n",
      "   micro avg       1.00      1.00      1.00    199364\n",
      "   macro avg       0.94      0.81      0.86    199364\n",
      "weighted avg       1.00      1.00      1.00    199364\n",
      " \n",
      "\n",
      "Test classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85296\n",
      "           1       0.88      0.62      0.73       147\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     85443\n",
      "   macro avg       0.94      0.81      0.86     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "perform_classification(linear_model.LogisticRegression(), X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Pridruziti tezine klasama proporcionalne velicini.\n",
    "\n",
    "Klasifikatori imaju argument `class_weight` koji ako je jednak `balanced` pridruzuje tezine klasama po formuli:\n",
    "$$\n",
    "w_j = \\frac{n}{k n_j}\n",
    "$$\n",
    "\n",
    "gde su:\n",
    "- $n$ - broj instanci\n",
    "- $n_j$: broj instanci klase j\n",
    "- $k$: broj klasa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/lib/python3.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train confusion matrix:\n",
      " [[194304   4715]\n",
      " [    29    316]] \n",
      "\n",
      "Test confusion matrix:\n",
      " [[83359  1937]\n",
      " [   13   134]] \n",
      "\n",
      "Train classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99    199019\n",
      "           1       0.06      0.92      0.12       345\n",
      "\n",
      "   micro avg       0.98      0.98      0.98    199364\n",
      "   macro avg       0.53      0.95      0.55    199364\n",
      "weighted avg       1.00      0.98      0.99    199364\n",
      " \n",
      "\n",
      "Test classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     85296\n",
      "           1       0.06      0.91      0.12       147\n",
      "\n",
      "   micro avg       0.98      0.98      0.98     85443\n",
      "   macro avg       0.53      0.94      0.55     85443\n",
      "weighted avg       1.00      0.98      0.99     85443\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = linear_model.LogisticRegression(random_state=0, class_weight='balanced')\n",
    "perform_classification(clf, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Nauciti optimalne vrednosti parametara tezina iz skupa $weights=np.linspace(0.05, 0.95, 20)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done   2 tasks      | elapsed:   11.6s\n",
      "[Parallel(n_jobs=3)]: Done   7 tasks      | elapsed:   31.3s\n",
      "[Parallel(n_jobs=3)]: Done  12 tasks      | elapsed:   47.2s\n",
      "[Parallel(n_jobs=3)]: Done  19 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=3)]: Done  26 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=3)]: Done  35 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=3)]: Done  44 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=3)]: Done  55 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=3)]: Done  60 out of  60 | elapsed:  4.8min finished\n",
      "/usr/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/lib/python3.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "weights = np.linspace(0.05, 0.95, 20)\n",
    "\n",
    "gsc = model_selection.GridSearchCV(\n",
    "    estimator=linear_model.LogisticRegression(),\n",
    "    param_grid={\n",
    "        'class_weight': [{0: x, 1: 1.0-x} for x in weights]\n",
    "    },\n",
    "    scoring='f1',\n",
    "    verbose=10,\n",
    "    n_jobs=3,\n",
    "    cv=3,\n",
    ")\n",
    "grid_result = gsc.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters : {'class_weight': {0: 0.14473684210526316, 1: 0.8552631578947368}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f134c255668>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Best parameters : %s\" % grid_result.best_params_)\n",
    "\n",
    "# Plot the weights vs f1 score\n",
    "dataz = pd.DataFrame({ 'score': grid_result.cv_results_['mean_test_score'],\n",
    "                       'weight': weights })\n",
    "dataz.plot(x='weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = {'C': 6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/lib/python3.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train confusion matrix:\n",
      " [[198946     73]\n",
      " [    65    280]] \n",
      "\n",
      "Test confusion matrix:\n",
      " [[85274    22]\n",
      " [   29   118]] \n",
      "\n",
      "Train classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    199019\n",
      "           1       0.79      0.81      0.80       345\n",
      "\n",
      "   micro avg       1.00      1.00      1.00    199364\n",
      "   macro avg       0.90      0.91      0.90    199364\n",
      "weighted avg       1.00      1.00      1.00    199364\n",
      " \n",
      "\n",
      "Test classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85296\n",
      "           1       0.84      0.80      0.82       147\n",
      "\n",
      "   micro avg       1.00      1.00      1.00     85443\n",
      "   macro avg       0.92      0.90      0.91     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = linear_model.LogisticRegression(**gsc.best_params_)\n",
    "perform_classification(clf, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) U nekim slucajevima je podesno koristiti metode sintetickog generisanja podataka. Jedan od najpoznatijih algoritama za generisanje instanci manjinske klase je SMOTE algoritam. Za svaku instancu manjinske klase se bira $k$ najblizih suseda (npr. k=5), a zatim se u zavisnosti od faktora uvecanja $scale$ (npr. scale = 200%) biraju svi susedi ili slucajno, samo neki od njih. Duz pravca koji vodi od instance manjinske klase ka susedu, generise se nova instanca (minority_instance + alpha*difference).   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "# from sklearn.pipeline import make_pipeline\n",
    "from imblearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before OverSampling, counts of label '1': [345]\n",
      "Before OverSampling, counts of label '0': [199019] \n",
      "\n",
      "After OverSampling, the shape of train_X: (398038, 29)\n",
      "After OverSampling, the shape of train_y: (398038,) \n",
      "\n",
      "After OverSampling, counts of label '1': 199019\n",
      "After OverSampling, counts of label '0': 199019\n"
     ]
    }
   ],
   "source": [
    "print(\"Before OverSampling, counts of label '1': {}\".format(sum(y_train==1)))\n",
    "print(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(y_train==0)))\n",
    "\n",
    "sm = SMOTE(random_state=2)\n",
    "X_train_res, y_train_res = sm.fit_sample(X_train, y_train.ravel())\n",
    "\n",
    "print('After OverSampling, the shape of train_X: {}'.format(X_train_res.shape))\n",
    "print('After OverSampling, the shape of train_y: {} \\n'.format(y_train_res.shape))\n",
    "\n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_res==1)))\n",
    "print(\"After OverSampling, counts of label '0': {}\".format(sum(y_train_res==0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train confusion matrix:\n",
      " [[193969   5050]\n",
      " [ 16784 182235]] \n",
      "\n",
      "Test confusion matrix:\n",
      " [[83193  2103]\n",
      " [   12   135]] \n",
      "\n",
      "Train classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.95    199019\n",
      "           1       0.97      0.92      0.94    199019\n",
      "\n",
      "   micro avg       0.95      0.95      0.95    398038\n",
      "   macro avg       0.95      0.95      0.95    398038\n",
      "weighted avg       0.95      0.95      0.95    398038\n",
      " \n",
      "\n",
      "Test classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     85296\n",
      "           1       0.06      0.92      0.11       147\n",
      "\n",
      "   micro avg       0.98      0.98      0.98     85443\n",
      "   macro avg       0.53      0.95      0.55     85443\n",
      "weighted avg       1.00      0.98      0.99     85443\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = perform_classification(linear_model.LogisticRegression(), X_train_res, y_train_res, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train confusion matrix:\n",
      " [[193976   5043]\n",
      " [    27    318]] \n",
      "\n",
      "Test confusion matrix:\n",
      " [[83202  2094]\n",
      " [   12   135]] \n",
      "\n",
      "Train classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99    199019\n",
      "           1       0.06      0.92      0.11       345\n",
      "\n",
      "   micro avg       0.97      0.97      0.97    199364\n",
      "   macro avg       0.53      0.95      0.55    199364\n",
      "weighted avg       1.00      0.97      0.99    199364\n",
      " \n",
      "\n",
      "Test classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     85296\n",
      "           1       0.06      0.92      0.11       147\n",
      "\n",
      "   micro avg       0.98      0.98      0.98     85443\n",
      "   macro avg       0.53      0.95      0.55     85443\n",
      "weighted avg       1.00      0.98      0.99     85443\n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe = make_pipeline(\n",
    "    SMOTE(),\n",
    "    linear_model.LogisticRegression()\n",
    ")\n",
    "\n",
    "perform_classification(pipe, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Takodje, koristeci SMOTE mozemo da primenimo GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LogisticRegression' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-ae05a5585dc3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m pipe = make_pipeline(\n\u001b[1;32m      2\u001b[0m     \u001b[0mSMOTE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m )\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'LogisticRegression' is not defined"
     ]
    }
   ],
   "source": [
    "pipe = make_pipeline(\n",
    "    SMOTE(),\n",
    "    linear_model.LogisticRegression()\n",
    ")\n",
    "\n",
    "weights = np.linspace(0.005, 0.05, 10)\n",
    "\n",
    "gsc = GridSearchCV(\n",
    "    estimator=pipe,\n",
    "    param_grid={\n",
    "        #'smote__ratio': [{0: int(num_neg), 1: int(num_neg * w) } for w in weights]\n",
    "        'smote__ratio': weights\n",
    "    },\n",
    "    scoring='f1',\n",
    "    verbose=10,\n",
    "    n_jobs=3,\n",
    "    cv=3\n",
    ")\n",
    "grid_result = gsc.fit(X, y)\n",
    "\n",
    "print(\"Best parameters : %s\" % grid_result.best_params_)\n",
    "\n",
    "# Plot the weights vs f1 score\n",
    "dataz = pd.DataFrame({ 'score': grid_result.cv_results_['mean_test_score'],\n",
    "                       'weight': weights })\n",
    "dataz.plot(x='weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
